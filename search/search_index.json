{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Introducing Virtuous AI VAI-UTILS is a automl package that enable users to automatically train ml models using hyperparameter optimization AutoML serves as an framework for automatic model training on all traditional classes of problems (image, text, numerical, categorical, and mixed prediction or classification). With VAI-UTILS, organizations can do most things. It allows for massive training to determine the best model and parameters. Virtuous AI's data pipelines are run on our own hardware, which is available for purchase, allowing organizations to handle large volumes of data and efficiently process it for machine learning tasks. With Virtuous AI's ModelOps hardware-software solution, organizations can unlock the full potential of their machine learning models. By automating the end-to-end model lifecycle, from data preparation to deployment, Virtuous AI empowers organizations to drive innovation and make accurate predictions based on their data.","title":"Introducing Virtuous AI"},{"location":"index.html#introducing-virtuous-ai","text":"VAI-UTILS is a automl package that enable users to automatically train ml models using hyperparameter optimization AutoML serves as an framework for automatic model training on all traditional classes of problems (image, text, numerical, categorical, and mixed prediction or classification). With VAI-UTILS, organizations can do most things. It allows for massive training to determine the best model and parameters. Virtuous AI's data pipelines are run on our own hardware, which is available for purchase, allowing organizations to handle large volumes of data and efficiently process it for machine learning tasks. With Virtuous AI's ModelOps hardware-software solution, organizations can unlock the full potential of their machine learning models. By automating the end-to-end model lifecycle, from data preparation to deployment, Virtuous AI empowers organizations to drive innovation and make accurate predictions based on their data.","title":"Introducing Virtuous AI"},{"location":"data_format.html","text":"Data Rules 1. Uploading Data Data is stored in csv's and zips. It is done by name to enable parallel distribution for data loading. CSV Files : Data should be stored in CSV format. Each CSV file should represent a dataset or a part of a dataset. Zip Files : If you have multiple CSV files for a single dataset, you can compress them into a zip file. This is useful for organizing related CSV files and reducing the storage space. . \u251c\u2500\u2500 data.zip \u2502 \u251c\u2500\u2500 location_01:01:22.csv \u2502 \u251c\u2500\u2500 location_01:02:22.csv \u2502 \u251c\u2500\u2500 location_01:03:22.csv \u2502 \u2514\u2500\u2500 ... 3. Data Format Files are stored with the format \"date:time.csv\". location_MM:DD:YY.csv: HH:MM:SS Age (Protected) Text (Input) Image (Input) Categorical (Input) Numerical (Input) \"12:34:56\" \"Age Input Example\" \"This is an example of text data.\" \"https://example.com/image.jpg\" \"Category1\" 123.45 Timestamps: \"HH:MM:SS\": If your data has a column for timestamps, use that column for timestamps. Otherwise, the current time will be used as the default timestamp. Warning Consistent Headers : If you're using multiple CSV files, ensure they all have the same header row for consistency and easier data processing. This helps to ensure that the data from different files can be combined or compared accurately. EXAMPLE You want your end table to look like something like the following workclass (Category) (Protected) Text (Input) (Text) Image (Input) (Image) Classif (Input) (Category) Score (Input) (Numerical) \"government\" \"This is an example of text data.\" \"https://example.com/image.jpg\" \"Category1\" 123.45 \"doctor\" \"This is an example of text data.\" \"https://example.com/image.jpg\" \"Category2\" 678.90 \"student\" \"This is an example of text data.\" \"https://example.com/image.jpg\" \"Category3\" 345.67","title":"2. Data Formal and Rules"},{"location":"data_format.html#data-rules","text":"","title":"Data Rules"},{"location":"data_format.html#1-uploading-data","text":"Data is stored in csv's and zips. It is done by name to enable parallel distribution for data loading. CSV Files : Data should be stored in CSV format. Each CSV file should represent a dataset or a part of a dataset. Zip Files : If you have multiple CSV files for a single dataset, you can compress them into a zip file. This is useful for organizing related CSV files and reducing the storage space. . \u251c\u2500\u2500 data.zip \u2502 \u251c\u2500\u2500 location_01:01:22.csv \u2502 \u251c\u2500\u2500 location_01:02:22.csv \u2502 \u251c\u2500\u2500 location_01:03:22.csv \u2502 \u2514\u2500\u2500 ...","title":"1. Uploading Data"},{"location":"data_format.html#3-data-format","text":"Files are stored with the format \"date:time.csv\". location_MM:DD:YY.csv: HH:MM:SS Age (Protected) Text (Input) Image (Input) Categorical (Input) Numerical (Input) \"12:34:56\" \"Age Input Example\" \"This is an example of text data.\" \"https://example.com/image.jpg\" \"Category1\" 123.45 Timestamps: \"HH:MM:SS\": If your data has a column for timestamps, use that column for timestamps. Otherwise, the current time will be used as the default timestamp. Warning Consistent Headers : If you're using multiple CSV files, ensure they all have the same header row for consistency and easier data processing. This helps to ensure that the data from different files can be combined or compared accurately.","title":"3. Data Format"},{"location":"data_format.html#example","text":"You want your end table to look like something like the following workclass (Category) (Protected) Text (Input) (Text) Image (Input) (Image) Classif (Input) (Category) Score (Input) (Numerical) \"government\" \"This is an example of text data.\" \"https://example.com/image.jpg\" \"Category1\" 123.45 \"doctor\" \"This is an example of text data.\" \"https://example.com/image.jpg\" \"Category2\" 678.90 \"student\" \"This is an example of text data.\" \"https://example.com/image.jpg\" \"Category3\" 345.67","title":"EXAMPLE"},{"location":"data_structure.html","text":"Data Uploads This project requires data to be structured according to the following guidelines: Required Labels There are three types of labels: Input, Output, and Protected. Input These labels are used for the input features in your model. Output These labels are used for the output or target variable that your model is trying to predict. Protected These labels are used for sensitive features that should be protected from bias. Feature Values/Types Columns that contain numerical, categorical, or text data should hold the actual values for these features. Each type of feature requires different preprocessing steps. Images Each CSV file should include a column for the image name. This column links each data sample to its corresponding image. There should be a specific column in the CSV file for image data. This column should contain the name of the image that corresponds to the other feature values in each row. The image specified by the name in the image data column should be loaded and associated with the corresponding feature values for each data sample. Text Text data should be preprocessed and converted into a format that can be used by the model. This may involve steps like tokenization, stemming, and vectorization. The preprocessed text data can then be used as input features for the model. Numerical Numerical data should be properly scaled or normalized before being used as input features for the model. This helps to ensure that the model doesn't give undue importance to features with larger scales. Categorical Categorical data should be encoded before being used as input features for the model. This can be done using techniques like one-hot encoding or ordinal encoding. The encoded categorical data can then be used as input features for the model.","title":"1. Data Structure"},{"location":"data_structure.html#data-uploads","text":"This project requires data to be structured according to the following guidelines:","title":"Data Uploads"},{"location":"data_structure.html#required-labels","text":"There are three types of labels: Input, Output, and Protected. Input These labels are used for the input features in your model. Output These labels are used for the output or target variable that your model is trying to predict. Protected These labels are used for sensitive features that should be protected from bias.","title":"Required Labels"},{"location":"data_structure.html#feature-valuestypes","text":"Columns that contain numerical, categorical, or text data should hold the actual values for these features. Each type of feature requires different preprocessing steps. Images Each CSV file should include a column for the image name. This column links each data sample to its corresponding image. There should be a specific column in the CSV file for image data. This column should contain the name of the image that corresponds to the other feature values in each row. The image specified by the name in the image data column should be loaded and associated with the corresponding feature values for each data sample. Text Text data should be preprocessed and converted into a format that can be used by the model. This may involve steps like tokenization, stemming, and vectorization. The preprocessed text data can then be used as input features for the model. Numerical Numerical data should be properly scaled or normalized before being used as input features for the model. This helps to ensure that the model doesn't give undue importance to features with larger scales. Categorical Categorical data should be encoded before being used as input features for the model. This can be done using techniques like one-hot encoding or ordinal encoding. The encoded categorical data can then be used as input features for the model.","title":"Feature Values/Types"},{"location":"endpoints.html","text":"The Endpoints Reference Guide repository for our Flask API provides detailed documentation for all API endpoints. It is a crucial resource for developers, offering specifics such as the HTTP method, path, request parameters, request body, response body, and potential status codes for each endpoint. This guide is integral to understanding how our Flask API interacts with data, aids in model training, prediction, and evaluation, and facilitates seamless development, debugging, and integration tasks.\" Setup in Python Run the following command on a deployed server import requests , json # Define the hyperparameters space with open ( \"payload.json\" , \"r+\" ) as f : space = json . loads () # Send a POST request to the automl Flask application response = requests . post ( 'http://api.virtuousai.com:5000/v1/automl' , json = space ) # Print the response print ( response . json ()) Endpoints Table 1. FlaskAPI Endpoints Endpoint HTTP Method Description /v1/model/train POST This endpoint is used to train a model using a specified dataset. /v1/model/predict POST This endpoint is used to make predictions using a trained model. /v1/model/explain POST This endpoint is used to evaluate a trained model.","title":"Endpoints"},{"location":"endpoints.html#setup-in-python","text":"Run the following command on a deployed server import requests , json # Define the hyperparameters space with open ( \"payload.json\" , \"r+\" ) as f : space = json . loads () # Send a POST request to the automl Flask application response = requests . post ( 'http://api.virtuousai.com:5000/v1/automl' , json = space ) # Print the response print ( response . json ())","title":"Setup in Python"},{"location":"endpoints.html#endpoints","text":"Table 1. FlaskAPI Endpoints Endpoint HTTP Method Description /v1/model/train POST This endpoint is used to train a model using a specified dataset. /v1/model/predict POST This endpoint is used to make predictions using a trained model. /v1/model/explain POST This endpoint is used to evaluate a trained model.","title":"Endpoints"},{"location":"example-explain.html","text":"Hyperopt 1: Create Pipeline w/ Data To create a pipeline, you have two options (se our API API or user interface (UX) to create a pipeline.) 2: Build a Docker If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image . 3: Create a Payload An example of possible training parameters might be the following (look at the API for more information) { \"next-item\" : { \"params\" : { \"timeseries\" : True , \"x\" : {}, \"y\" : {}, \"pipeline\" : \"2890379nvjs\" \"user_secret\" : \"lkjho823hikuwn\" } } } You can call it from python using the following. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/explain","title":"4. Explain Example"},{"location":"example-explain.html#hyperopt","text":"","title":"Hyperopt"},{"location":"example-explain.html#1-create-pipeline-w-data","text":"To create a pipeline, you have two options (se our API API or user interface (UX) to create a pipeline.)","title":"1: Create Pipeline w/ Data"},{"location":"example-explain.html#2-build-a-docker","text":"If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image .","title":"2: Build a Docker"},{"location":"example-explain.html#3-create-a-payload","text":"An example of possible training parameters might be the following (look at the API for more information) { \"next-item\" : { \"params\" : { \"timeseries\" : True , \"x\" : {}, \"y\" : {}, \"pipeline\" : \"2890379nvjs\" \"user_secret\" : \"lkjho823hikuwn\" } } } You can call it from python using the following. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/explain","title":"3:  Create a Payload"},{"location":"example-hyperopt.html","text":"Hyperopt 1: Create Pipeline w/ Data To create a pipeline, you have two options (se our API API or user interface (UX) to create a pipeline.) 2: Build a Docker If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image . 3: Create a Payload An example of possible training parameters might be the following (look at the API for more information) { \"url\" : \"https://dev-cloud-api.virtuousai.com/api/v1/explainability-model-ml-callback\" , \"mid\" : \"rory-testing\" , \"file_paths\" : [ \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62ef6cbdca16470013492ebd/62ef6ce0ca16470013492ee0/07:42:24/06-24-2022.csv\" , \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62ef6cbdca16470013492ebd/62ef6ce1ca164700134932de/07:42:25/06-25-2022.csv\" ], \"x\" : { \"age\" : { \"type\" : \"NUMBER\" , \"null\" : \"mean\" }, \"workclass\" : { \"type\" : \"CATEGORY\" }, \"capital-gain\" : { \"type\" : \"NUMBER\" } }, \"y\" : { \"loan-approved\" : { \"type\" : \"CATEGORY\" } } } You can call it from python using the following. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/hyperopt","title":"1. Hyperopt Example"},{"location":"example-hyperopt.html#hyperopt","text":"","title":"Hyperopt"},{"location":"example-hyperopt.html#1-create-pipeline-w-data","text":"To create a pipeline, you have two options (se our API API or user interface (UX) to create a pipeline.)","title":"1: Create Pipeline w/ Data"},{"location":"example-hyperopt.html#2-build-a-docker","text":"If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image .","title":"2: Build a Docker"},{"location":"example-hyperopt.html#3-create-a-payload","text":"An example of possible training parameters might be the following (look at the API for more information) { \"url\" : \"https://dev-cloud-api.virtuousai.com/api/v1/explainability-model-ml-callback\" , \"mid\" : \"rory-testing\" , \"file_paths\" : [ \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62ef6cbdca16470013492ebd/62ef6ce0ca16470013492ee0/07:42:24/06-24-2022.csv\" , \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62ef6cbdca16470013492ebd/62ef6ce1ca164700134932de/07:42:25/06-25-2022.csv\" ], \"x\" : { \"age\" : { \"type\" : \"NUMBER\" , \"null\" : \"mean\" }, \"workclass\" : { \"type\" : \"CATEGORY\" }, \"capital-gain\" : { \"type\" : \"NUMBER\" } }, \"y\" : { \"loan-approved\" : { \"type\" : \"CATEGORY\" } } } You can call it from python using the following. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/hyperopt","title":"3:  Create a Payload"},{"location":"example-learn.html","text":"Learn 1: Create Pipeline w/ Data To create a pipeline, you have two options (se our API API or user interface (UX) to create a pipeline.) 2: Build a Docker If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image . 3: Create a Payload An example of possible training parameters might be the following (look at the API for more information) { \"mid\" : \"rory-testing\" , \"file_paths\" : [ \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62e94f4abcef02001321c5ed/62ef37dcca164700134416bb/03:56:12/06-22-2022.csv\" , \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62e94f4abcef02001321c5ed/62ef37deca16470013441ab9/03:56:14/06-23-2022.csv\" ], \"x\" : { \"age\" : { \"type\" : \"NUMBER\" , \"null\" : \"mean\" }, \"workclass\" : { \"type\" : \"CATEGORY\" }, \"capital-gain\" : { \"type\" : \"NUMBER\" } }, \"y\" : { \"loan-approved\" : { \"type\" : \"CATEGORY\" } }, \"h_params\" : { \"learning_rate\" : \".1\" , \"epochs\" : 100 , \"batch_size\" : 1024 , \"deep_lyrs\" : 0 , \"tid\" : 1 }, \"null\" : \"infer\" } You can call it from python using the following. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/fit","title":"2. Learn Example"},{"location":"example-learn.html#learn","text":"","title":"Learn"},{"location":"example-learn.html#1-create-pipeline-w-data","text":"To create a pipeline, you have two options (se our API API or user interface (UX) to create a pipeline.)","title":"1: Create Pipeline w/ Data"},{"location":"example-learn.html#2-build-a-docker","text":"If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image .","title":"2: Build a Docker"},{"location":"example-learn.html#3-create-a-payload","text":"An example of possible training parameters might be the following (look at the API for more information) { \"mid\" : \"rory-testing\" , \"file_paths\" : [ \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62e94f4abcef02001321c5ed/62ef37dcca164700134416bb/03:56:12/06-22-2022.csv\" , \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62e94f4abcef02001321c5ed/62ef37deca16470013441ab9/03:56:14/06-23-2022.csv\" ], \"x\" : { \"age\" : { \"type\" : \"NUMBER\" , \"null\" : \"mean\" }, \"workclass\" : { \"type\" : \"CATEGORY\" }, \"capital-gain\" : { \"type\" : \"NUMBER\" } }, \"y\" : { \"loan-approved\" : { \"type\" : \"CATEGORY\" } }, \"h_params\" : { \"learning_rate\" : \".1\" , \"epochs\" : 100 , \"batch_size\" : 1024 , \"deep_lyrs\" : 0 , \"tid\" : 1 }, \"null\" : \"infer\" } You can call it from python using the following. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/fit","title":"3:  Create a Payload"},{"location":"example-predict.html","text":"Hyperopt 1: Create Pipeline w/ Data To create a pipeline, you have two options (se our API API or user interface (UX) to create a pipeline.) 2: Build a Docker If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image . 3: Create a Payload An example of possible training parameters might be the following (look at the API for more information) { \"model\" : \"dev/models/5e2b87ebb0b0ec73f52aa0a0/62bb66a09a4f3c0013cad5e5/62c4ae34ef24f50014b1beb4_0.1_1_1_0_0_0\" , \"file_paths\" : [ \"prod/dataset-files/61fb5b529ea6c200137eacce/62d6f676cebf7200153c2612/62d6f689cebf7200153c2632/11:23:03/07-19-2022.csv\" ], \"x\" : { \"sex\" : { \"type\" : \"STRING\" , \"values\" : [ \"Male Female Male\" ] } }, \"y\" : { \"income-per-year\" : { \"type\" : \"CATEGORY\" } } } You can call it from python using the following. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/predict","title":"3. Predict Example"},{"location":"example-predict.html#hyperopt","text":"","title":"Hyperopt"},{"location":"example-predict.html#1-create-pipeline-w-data","text":"To create a pipeline, you have two options (se our API API or user interface (UX) to create a pipeline.)","title":"1: Create Pipeline w/ Data"},{"location":"example-predict.html#2-build-a-docker","text":"If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image .","title":"2: Build a Docker"},{"location":"example-predict.html#3-create-a-payload","text":"An example of possible training parameters might be the following (look at the API for more information) { \"model\" : \"dev/models/5e2b87ebb0b0ec73f52aa0a0/62bb66a09a4f3c0013cad5e5/62c4ae34ef24f50014b1beb4_0.1_1_1_0_0_0\" , \"file_paths\" : [ \"prod/dataset-files/61fb5b529ea6c200137eacce/62d6f676cebf7200153c2612/62d6f689cebf7200153c2632/11:23:03/07-19-2022.csv\" ], \"x\" : { \"sex\" : { \"type\" : \"STRING\" , \"values\" : [ \"Male Female Male\" ] } }, \"y\" : { \"income-per-year\" : { \"type\" : \"CATEGORY\" } } } You can call it from python using the following. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/predict","title":"3:  Create a Payload"},{"location":"explain.html","text":"Explain Method Description explain.load_data(file) loads data to the program explain.load_model(file) Use to insert model in bulk explain.fit(file) Use to insert bulk users, pipelines, locations and accesses in bulk 1.explain.call_enpoint(file) explain . call_endpoint ( file_path ) PAYLOAD { \"model\" : \"dev/models/5e2b87ebb0b0ec73f52aa0a0/62bb66a09a4f3c0013cad5e5/62c4ae34ef24f50014b1beb4_0.1_1_1_0_0_0\" , \"file_paths\" : [ \"prod/dataset-files/61fb5b529ea6c200137eacce/62d6f676cebf7200153c2612/62d6f689cebf7200153c2632/11:23:03/07-19-2022.csv\" ], \"x\" : { \"sex\" : { \"type\" : \"STRING\" , \"values\" : [ \"Male Female Male\" ] } }, \"y\" : { \"income-per-year\" : { \"type\" : \"CATEGORY\" } } }","title":"3. Explain"},{"location":"explain.html#explain","text":"Method Description explain.load_data(file) loads data to the program explain.load_model(file) Use to insert model in bulk explain.fit(file) Use to insert bulk users, pipelines, locations and accesses in bulk","title":"Explain"},{"location":"explain.html#1explaincall_enpointfile","text":"explain . call_endpoint ( file_path )","title":"1.explain.call_enpoint(file)"},{"location":"explain.html#payload","text":"{ \"model\" : \"dev/models/5e2b87ebb0b0ec73f52aa0a0/62bb66a09a4f3c0013cad5e5/62c4ae34ef24f50014b1beb4_0.1_1_1_0_0_0\" , \"file_paths\" : [ \"prod/dataset-files/61fb5b529ea6c200137eacce/62d6f676cebf7200153c2612/62d6f689cebf7200153c2632/11:23:03/07-19-2022.csv\" ], \"x\" : { \"sex\" : { \"type\" : \"STRING\" , \"values\" : [ \"Male Female Male\" ] } }, \"y\" : { \"income-per-year\" : { \"type\" : \"CATEGORY\" } } }","title":"PAYLOAD"},{"location":"hyperopt.html","text":"HyperOpt for AutoML HyperOpt is a powerful Python library for hyperparameter optimization. In the context of our AutoML application, we use HyperOpt as a wrapper for the learning algorithm. It creates many instances of the model with different hyperparameters, which can later be called to make predictions or explanations. Steps to Use HyperOpt with AutoML Build the docker : If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image . Define the Search Space : HyperOpt requires a search space for the hyperparameters. This is a dictionary that defines the range of values for each hyperparameter. Here's an example: import requests , json # Define the hyperparameters space with open ( \"payload.json\" , \"r+\" ) as f : space = json . loads () # Send a POST request to the automl Flask application response = requests . post ( 'http://api.virtuousai.com:5000/v1/automl' , json = space ) # Print the response print ( response . json ()) PAYLOAD An example of possible training parameters might be the following (look at the API for more information) { \"url\" : \"https://dev-cloud-api.virtuousai.com/api/v1/explainability-model-ml-callback\" , \"mid\" : \"rory-testing\" , \"file_paths\" : [ \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62ef6cbdca16470013492ebd/62ef6ce0ca16470013492ee0/07:42:24/06-24-2022.csv\" , \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62ef6cbdca16470013492ebd/62ef6ce1ca164700134932de/07:42:25/06-25-2022.csv\" ], \"x\" : { \"age\" : { \"type\" : \"NUMBER\" , \"null\" : \"mean\" }, \"workclass\" : { \"type\" : \"CATEGORY\" }, \"capital-gain\" : { \"type\" : \"NUMBER\" } }, \"y\" : { \"loan-approved\" : { \"type\" : \"CATEGORY\" } } }","title":"1. Hyperopt"},{"location":"hyperopt.html#hyperopt-for-automl","text":"HyperOpt is a powerful Python library for hyperparameter optimization. In the context of our AutoML application, we use HyperOpt as a wrapper for the learning algorithm. It creates many instances of the model with different hyperparameters, which can later be called to make predictions or explanations.","title":"HyperOpt for AutoML"},{"location":"hyperopt.html#steps-to-use-hyperopt-with-automl","text":"Build the docker : If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image . Define the Search Space : HyperOpt requires a search space for the hyperparameters. This is a dictionary that defines the range of values for each hyperparameter. Here's an example: import requests , json # Define the hyperparameters space with open ( \"payload.json\" , \"r+\" ) as f : space = json . loads () # Send a POST request to the automl Flask application response = requests . post ( 'http://api.virtuousai.com:5000/v1/automl' , json = space ) # Print the response print ( response . json ())","title":"Steps to Use HyperOpt with AutoML"},{"location":"hyperopt.html#payload","text":"An example of possible training parameters might be the following (look at the API for more information) { \"url\" : \"https://dev-cloud-api.virtuousai.com/api/v1/explainability-model-ml-callback\" , \"mid\" : \"rory-testing\" , \"file_paths\" : [ \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62ef6cbdca16470013492ebd/62ef6ce0ca16470013492ee0/07:42:24/06-24-2022.csv\" , \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62ef6cbdca16470013492ebd/62ef6ce1ca164700134932de/07:42:25/06-25-2022.csv\" ], \"x\" : { \"age\" : { \"type\" : \"NUMBER\" , \"null\" : \"mean\" }, \"workclass\" : { \"type\" : \"CATEGORY\" }, \"capital-gain\" : { \"type\" : \"NUMBER\" } }, \"y\" : { \"loan-approved\" : { \"type\" : \"CATEGORY\" } } }","title":"PAYLOAD"},{"location":"image_model_params.html","text":"Image Model Learning Parameters The image_model_params.md file serves as a comprehensive guide to the parameters utilized in our AutoML application specifically for training image models. There are two types of parameters: image-specific and general. Image-specific parameters are grouped under the image_model key. This key defines the name of the image model and its corresponding parameters. On the other hand, general parameters apply to all models and are used to configure settings such as the optimizer, learning rate, momentum, epochs, batch size, and the number of hidden layers. This arrangement provides a flexible and efficient way to adjust the model parameters, thereby aiding in the creation of highly precise image models. Refer to the following for more details. { \"image_model\" : { \"mobilenet_v3_small_100_224\" : { \"use_dropout_img_layer\" : true , \"dropout_rate_img_layer\" : 0.2 , \"fine_tune_img_model\" : false , \"do_image_rescaling\" : true } }, \"optimizer\" : \"Adam\" , \"learning_rate\" : 1e-4 , \"momentum\" : 0.85 , \"epochs\" : 1 , \"batch_size\" : 64 , \"hidden_lyrs\" : 1 } Image Specific Parameters Below are the following options image_model : (str) Name of pre-trained image model, which is used to generate image embeddings. Currently default model is \"mobilenet_v3_small_100_224\". (NOTE: Names of different models can be copied/taken from image_pretrained.py). use_dropout_img_layer : (bool) If True, dropout is used to set some units activation to zero. Acts as regularization mechanism. Optional, defaults to True. dropout_rate_img_layer : (float 0-1) If \"use_dropout_img_layer\" is True, then the fraction of activation units to set to zero to act as regularization mechanism. Optional, defaults to 0.2. fine_tune_img_model : (bool) If True, image model \"trainable\" param is set to True, and image model weights are updated with training. Otherwise, weights of model are frozen, and only used to generate embeddings. Recommended to be set to False, unless data volume is huge. Optional, defaults to False. do_image_rescaling : (bool) If True, image values are divided by 255 to convert image from int8 RGB image (pixels from 0 - 255) to float RGB image (pixels from 0 - 1). Tensorflow expects input image data to be in float, so better to do this rescaling if unsure of image format. Optional, defaults to True. Other General Parameters optimizer : (str) The optimization algorithm to use. Example: \"Adam\". learning_rate : (float) The learning rate for the optimizer. Example: 1e-4. momentum : (float) The momentum factor for the optimizer. Example: 0.85. epochs : (int) The number of training epochs. Example: 1. batch_size : (int) The batch size for training. Example: 64. hidden_lyrs : (int) The number of hidden layers in the model. Example: 1.","title":"1. Image Models"},{"location":"image_model_params.html#image-model-learning-parameters","text":"The image_model_params.md file serves as a comprehensive guide to the parameters utilized in our AutoML application specifically for training image models. There are two types of parameters: image-specific and general. Image-specific parameters are grouped under the image_model key. This key defines the name of the image model and its corresponding parameters. On the other hand, general parameters apply to all models and are used to configure settings such as the optimizer, learning rate, momentum, epochs, batch size, and the number of hidden layers. This arrangement provides a flexible and efficient way to adjust the model parameters, thereby aiding in the creation of highly precise image models. Refer to the following for more details. { \"image_model\" : { \"mobilenet_v3_small_100_224\" : { \"use_dropout_img_layer\" : true , \"dropout_rate_img_layer\" : 0.2 , \"fine_tune_img_model\" : false , \"do_image_rescaling\" : true } }, \"optimizer\" : \"Adam\" , \"learning_rate\" : 1e-4 , \"momentum\" : 0.85 , \"epochs\" : 1 , \"batch_size\" : 64 , \"hidden_lyrs\" : 1 }","title":"Image Model Learning Parameters"},{"location":"image_model_params.html#image-specific-parameters","text":"Below are the following options image_model : (str) Name of pre-trained image model, which is used to generate image embeddings. Currently default model is \"mobilenet_v3_small_100_224\". (NOTE: Names of different models can be copied/taken from image_pretrained.py). use_dropout_img_layer : (bool) If True, dropout is used to set some units activation to zero. Acts as regularization mechanism. Optional, defaults to True. dropout_rate_img_layer : (float 0-1) If \"use_dropout_img_layer\" is True, then the fraction of activation units to set to zero to act as regularization mechanism. Optional, defaults to 0.2. fine_tune_img_model : (bool) If True, image model \"trainable\" param is set to True, and image model weights are updated with training. Otherwise, weights of model are frozen, and only used to generate embeddings. Recommended to be set to False, unless data volume is huge. Optional, defaults to False. do_image_rescaling : (bool) If True, image values are divided by 255 to convert image from int8 RGB image (pixels from 0 - 255) to float RGB image (pixels from 0 - 1). Tensorflow expects input image data to be in float, so better to do this rescaling if unsure of image format. Optional, defaults to True.","title":"Image Specific Parameters"},{"location":"image_model_params.html#other-general-parameters","text":"optimizer : (str) The optimization algorithm to use. Example: \"Adam\". learning_rate : (float) The learning rate for the optimizer. Example: 1e-4. momentum : (float) The momentum factor for the optimizer. Example: 0.85. epochs : (int) The number of training epochs. Example: 1. batch_size : (int) The batch size for training. Example: 64. hidden_lyrs : (int) The number of hidden layers in the model. Example: 1.","title":"Other General Parameters"},{"location":"learn.html","text":"Learn Method Description learn.load_data(file) loads data to the program learn.load_model(file) Use to insert model in bulk learn.fit(file) Use to insert bulk users, pipelines, locations and accesses in bulk 1.learn.call_enpoint(file) learn . call_endpoint ( file_path ) { \"mid\" : \"rory-testing\" , \"file_paths\" : [ \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62e94f4abcef02001321c5ed/62ef37dcca164700134416bb/03:56:12/06-22-2022.csv\" , \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62e94f4abcef02001321c5ed/62ef37deca16470013441ab9/03:56:14/06-23-2022.csv\" ], \"x\" : { \"age\" : { \"type\" : \"NUMBER\" , \"null\" : \"mean\" }, \"workclass\" : { \"type\" : \"CATEGORY\" }, \"capital-gain\" : { \"type\" : \"NUMBER\" } }, \"y\" : { \"loan-approved\" : { \"type\" : \"CATEGORY\" } }, \"h_params\" : { \"learning_rate\" : \".1\" , \"epochs\" : 100 , \"batch_size\" : 1024 , \"deep_lyrs\" : 0 , \"tid\" : 1 }, \"null\" : \"infer\" }","title":"2. Learn"},{"location":"learn.html#learn","text":"Method Description learn.load_data(file) loads data to the program learn.load_model(file) Use to insert model in bulk learn.fit(file) Use to insert bulk users, pipelines, locations and accesses in bulk","title":"Learn"},{"location":"learn.html#1learncall_enpointfile","text":"learn . call_endpoint ( file_path ) { \"mid\" : \"rory-testing\" , \"file_paths\" : [ \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62e94f4abcef02001321c5ed/62ef37dcca164700134416bb/03:56:12/06-22-2022.csv\" , \"dev/dataset-files/5e2b87ebb0b0ec73f52aa0a0/62e94f4abcef02001321c5ed/62ef37deca16470013441ab9/03:56:14/06-23-2022.csv\" ], \"x\" : { \"age\" : { \"type\" : \"NUMBER\" , \"null\" : \"mean\" }, \"workclass\" : { \"type\" : \"CATEGORY\" }, \"capital-gain\" : { \"type\" : \"NUMBER\" } }, \"y\" : { \"loan-approved\" : { \"type\" : \"CATEGORY\" } }, \"h_params\" : { \"learning_rate\" : \".1\" , \"epochs\" : 100 , \"batch_size\" : 1024 , \"deep_lyrs\" : 0 , \"tid\" : 1 }, \"null\" : \"infer\" }","title":"1.learn.call_enpoint(file)"},{"location":"overview.html","text":"1. Overview The Virtuous ModelOps Heirarchy Many functions to one model. One scalable pod controlled by kubernets. But permissions are required to access a pipeline, which not even VirtuousAI employees will have access to. AutoML.py Calling the Endpoint Call the API like the following. import requests , json # Define the hyperparameters space with open ( \"payload.json\" , \"r+\" ) as f : space = json . loads () # Send a POST request to the automl Flask application response = requests . post ( 'http://api.virtuousai.com:5000/v1/automl' , json = space ) # Print the response print ( response . json ()) The Endpoints Below are the category of API calls to interact with the AUTOML (our legacy model) suite. Instance Description Additional Information hyperopt.call_hyperopt The controller for AUTOML. Calls multiple learn instances given the params. First, you call the hyperopt endpoint to create multiple models using the learn endpoint. Hyperopt does the job scheduling. To be replaced by Tensorflow and Katib most likely. learn.call_learn The training/fit instance. It produces the trained model that is used. Each hyperopt job schedules multiple other learn jobs wherever resources provide. predict.call_predict The classification/prediction instance. It is accessible after training has been performed. After \"learning\" is finished, a single model instance is preserved and the rest are killed and data deleted. The remaining instances are now live and callable for prediction. explain.call_explain The explain instance. It is accessible after training has been performed. In summary, it is feature importance, contribution, that the specific model provides. In addition to prediction, you can also perform explanation for predictions to justify results. These vary based on model type. See your applicable product type to see the methods available. But they may include the following: feature contribution, feature importance, data drift, bias. (See the next section for an introduction)","title":"2. System Overview"},{"location":"overview.html#1-overview","text":"","title":"1. Overview"},{"location":"overview.html#the-virtuous-modelops-heirarchy","text":"Many functions to one model. One scalable pod controlled by kubernets. But permissions are required to access a pipeline, which not even VirtuousAI employees will have access to. AutoML.py","title":"The Virtuous ModelOps Heirarchy"},{"location":"overview.html#calling-the-endpoint","text":"Call the API like the following. import requests , json # Define the hyperparameters space with open ( \"payload.json\" , \"r+\" ) as f : space = json . loads () # Send a POST request to the automl Flask application response = requests . post ( 'http://api.virtuousai.com:5000/v1/automl' , json = space ) # Print the response print ( response . json ())","title":"Calling the Endpoint"},{"location":"overview.html#the-endpoints","text":"Below are the category of API calls to interact with the AUTOML (our legacy model) suite. Instance Description Additional Information hyperopt.call_hyperopt The controller for AUTOML. Calls multiple learn instances given the params. First, you call the hyperopt endpoint to create multiple models using the learn endpoint. Hyperopt does the job scheduling. To be replaced by Tensorflow and Katib most likely. learn.call_learn The training/fit instance. It produces the trained model that is used. Each hyperopt job schedules multiple other learn jobs wherever resources provide. predict.call_predict The classification/prediction instance. It is accessible after training has been performed. After \"learning\" is finished, a single model instance is preserved and the rest are killed and data deleted. The remaining instances are now live and callable for prediction. explain.call_explain The explain instance. It is accessible after training has been performed. In summary, it is feature importance, contribution, that the specific model provides. In addition to prediction, you can also perform explanation for predictions to justify results. These vary based on model type. See your applicable product type to see the methods available. But they may include the following: feature contribution, feature importance, data drift, bias. (See the next section for an introduction)","title":"The Endpoints"},{"location":"payload_info.html","text":"Payload DATA The payload is a JSON object with the following structure: 1. Input Features ( x ) This is a dictionary where each key is a feature name (must be same as in CSV file) and the value is another dictionary containing the following key/value pairs: type : (string) Value must be one of \"NUMBER\", \"CATEGORY\", \"STRING\", \"IMAGE\". null : (string) Optional for numerical features (NUMBER). Currently only supports \"mean\", i.e. replace null/missing values with mean of feature. 2. Output/Predicted Features ( y ) This is a dictionary where each key is a feature name (must be same as in CSV file) and the value is another dictionary containing the following key/value pairs: type : (string) Value must be one of \"NUMBER\" or \"CATEGORY\" (can't be STRING or IMAGE). For example, multiple outputs are supported: { \"AdoptionSpeed\" : { \"type\" : \"CATEGORY\" }, \"Type\" : { \"type\" : \"CATEGORY\" }, } META DATA The following parameters are also needed. mid : (string) Model ID, must be unique for every model. url : (string) URL for some logging endpoint. img_data_from_S3 : (bool) Whether to download image data from S3 or directly from some url. Currently only supports from S3, so fix it to True. overwrite_data : (bool) If False, data already downloaded would not be downloaded and extracted again. If True, previous data would be overwritten everytime. This is to avoid multiple downloads of data, when experimenting with parameters. normalize_numerical_cols : (bool) Whether to normalize numerical columns or not. Recommended to be True, to improve training accuracy. csv_file_paths : (list of strings) Each element in list must be path to CSV file in S3 bucket which shall be downloaded. e.g. [\"dev/pet-dataset-files/csv-data/pet_data.csv\"], img_file_paths : (list of strings) Each element in list must be path to ZIP file in S3 bucket which shall be downloaded and then extracted to some root folder. e.g. [\"dev/pet-dataset-files/img-data/pet_train_images.zip\"], (NOTE: It is the responsibility of user to ensure that images in ZIP file have same name as given in CSV file) See examples section to see how to put it all together.","title":"3. Understanding Payloads"},{"location":"payload_info.html#payload","text":"","title":"Payload"},{"location":"payload_info.html#data","text":"The payload is a JSON object with the following structure:","title":"DATA"},{"location":"payload_info.html#1-input-features-x","text":"This is a dictionary where each key is a feature name (must be same as in CSV file) and the value is another dictionary containing the following key/value pairs: type : (string) Value must be one of \"NUMBER\", \"CATEGORY\", \"STRING\", \"IMAGE\". null : (string) Optional for numerical features (NUMBER). Currently only supports \"mean\", i.e. replace null/missing values with mean of feature.","title":"1. Input Features (x)"},{"location":"payload_info.html#2-outputpredicted-features-y","text":"This is a dictionary where each key is a feature name (must be same as in CSV file) and the value is another dictionary containing the following key/value pairs: type : (string) Value must be one of \"NUMBER\" or \"CATEGORY\" (can't be STRING or IMAGE). For example, multiple outputs are supported: { \"AdoptionSpeed\" : { \"type\" : \"CATEGORY\" }, \"Type\" : { \"type\" : \"CATEGORY\" }, }","title":"2. Output/Predicted Features (y)"},{"location":"payload_info.html#meta-data","text":"The following parameters are also needed. mid : (string) Model ID, must be unique for every model. url : (string) URL for some logging endpoint. img_data_from_S3 : (bool) Whether to download image data from S3 or directly from some url. Currently only supports from S3, so fix it to True. overwrite_data : (bool) If False, data already downloaded would not be downloaded and extracted again. If True, previous data would be overwritten everytime. This is to avoid multiple downloads of data, when experimenting with parameters. normalize_numerical_cols : (bool) Whether to normalize numerical columns or not. Recommended to be True, to improve training accuracy. csv_file_paths : (list of strings) Each element in list must be path to CSV file in S3 bucket which shall be downloaded. e.g. [\"dev/pet-dataset-files/csv-data/pet_data.csv\"], img_file_paths : (list of strings) Each element in list must be path to ZIP file in S3 bucket which shall be downloaded and then extracted to some root folder. e.g. [\"dev/pet-dataset-files/img-data/pet_train_images.zip\"], (NOTE: It is the responsibility of user to ensure that images in ZIP file have same name as given in CSV file) See examples section to see how to put it all together.","title":"META DATA"},{"location":"pipeline.html","text":"Pipelines 1: Create Pipeline w/ Data To create a pipeline, you have two options (se our API API or user interface (UX) to create a pipeline.) 2: Run AUTOML (via Hyperparameter Optimization) Next, we must create objects for the end users to interact with. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/fit 3: Predict After some time for training, say 15 minutes, you can add widgets to those models. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/predict 4: Explain Lastly, we can create events to track events such as data drift. (This may indicate that there is a problem that needs to be addressed). curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/explain This will be triggered based on whatever your metrics you defined.","title":"3. Worflow Process"},{"location":"pipeline.html#pipelines","text":"","title":"Pipelines"},{"location":"pipeline.html#1-create-pipeline-w-data","text":"To create a pipeline, you have two options (se our API API or user interface (UX) to create a pipeline.)","title":"1: Create Pipeline w/ Data"},{"location":"pipeline.html#2-run-automl-via-hyperparameter-optimization","text":"Next, we must create objects for the end users to interact with. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/fit","title":"2:  Run AUTOML (via Hyperparameter Optimization)"},{"location":"pipeline.html#3-predict","text":"After some time for training, say 15 minutes, you can add widgets to those models. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/v1/predict","title":"3: Predict"},{"location":"pipeline.html#4-explain","text":"Lastly, we can create events to track events such as data drift. (This may indicate that there is a problem that needs to be addressed). curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/explain This will be triggered based on whatever your metrics you defined.","title":"4:  Explain"},{"location":"predict.html","text":"Predict Method Description learn.load_model(file) Use to insert model in bulk predict.fit(file) Use to insert bulk users, pipelines, locations and accesses in bulk 1.predict.call_enpoint(file) predict . call_endpoint ( file_path ) PAYLOAD { \"model\" : \"dev/models/5e2b87ebb0b0ec73f52aa0a0/62bb66a09a4f3c0013cad5e5/62c4ae34ef24f50014b1beb4_0.1_1_1_0_0_0\" , \"file_paths\" : [ \"prod/dataset-files/61fb5b529ea6c200137eacce/62d6f676cebf7200153c2612/62d6f689cebf7200153c2632/11:23:03/07-19-2022.csv\" ], \"x\" : { \"sex\" : { \"type\" : \"STRING\" , \"values\" : [ \"Male Female Male\" ] } }, \"y\" : { \"income-per-year\" : { \"type\" : \"CATEGORY\" } } }","title":"Predict"},{"location":"predict.html#predict","text":"Method Description learn.load_model(file) Use to insert model in bulk predict.fit(file) Use to insert bulk users, pipelines, locations and accesses in bulk","title":"Predict"},{"location":"predict.html#1predictcall_enpointfile","text":"predict . call_endpoint ( file_path )","title":"1.predict.call_enpoint(file)"},{"location":"predict.html#payload","text":"{ \"model\" : \"dev/models/5e2b87ebb0b0ec73f52aa0a0/62bb66a09a4f3c0013cad5e5/62c4ae34ef24f50014b1beb4_0.1_1_1_0_0_0\" , \"file_paths\" : [ \"prod/dataset-files/61fb5b529ea6c200137eacce/62d6f676cebf7200153c2612/62d6f689cebf7200153c2632/11:23:03/07-19-2022.csv\" ], \"x\" : { \"sex\" : { \"type\" : \"STRING\" , \"values\" : [ \"Male Female Male\" ] } }, \"y\" : { \"income-per-year\" : { \"type\" : \"CATEGORY\" } } }","title":"PAYLOAD"},{"location":"python-guide.html","text":"Python Guide This is our Python Guide for ML development. See Tables. Below 1. Setup - Before Every Deployment If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image . 2. Call an Endpoint Table 1. vai_toolkit.model() Table 1. FlaskAPI Endpoints Endpoint HTTP Method Description /v1/model/train POST This endpoint is used to train a model using a specified dataset. /v1/model/predict POST This endpoint is used to make predictions using a trained model. /v1/model/explain POST This endpoint is used to evaluate a trained model. import requests , json # Define the hyperparameters space with open ( \"payload.json\" , \"r+\" ) as f : space = json . loads () # Send a POST request to the automl Flask application response = requests . post ( 'http://api.virtuousai.com:5000/v1/automl' , json = space ) # Print the response print ( response . json ())","title":"Overview"},{"location":"python-guide.html#python-guide","text":"This is our Python Guide for ML development. See Tables. Below","title":"Python Guide"},{"location":"python-guide.html#1-setup-before-every-deployment","text":"If you haven't already, you'll need to install the environment. You can do this with pip: docker build -t my-image .","title":"1. Setup - Before Every Deployment"},{"location":"python-guide.html#2-call-an-endpoint","text":"Table 1. vai_toolkit.model() Table 1. FlaskAPI Endpoints Endpoint HTTP Method Description /v1/model/train POST This endpoint is used to train a model using a specified dataset. /v1/model/predict POST This endpoint is used to make predictions using a trained model. /v1/model/explain POST This endpoint is used to evaluate a trained model. import requests , json # Define the hyperparameters space with open ( \"payload.json\" , \"r+\" ) as f : space = json . loads () # Send a POST request to the automl Flask application response = requests . post ( 'http://api.virtuousai.com:5000/v1/automl' , json = space ) # Print the response print ( response . json ())","title":"2. Call an Endpoint"},{"location":"quickstart.html","text":"QUICKSTART VAI Toolkit VAI-UTILS is the API for interacting the AUTOML suite. It provides a suite of tools and functionalities to automatically leearn, predict, and explain for all types of data. It can be used for most prediction and classification problems. Warning It is not yet capable of enabling chatbot or other generative AI tasks. 1. Building Apps To get started with VAI-UTILS, with a use a user key and a pipeline with data, follow these steps: Install VAI Toolkit by running the following command: docker build . curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/endpoint 2. Serving/Deploying Apps After testing locally, deploying is done automatically using gitlab CI-CD with the correct configurations. With \"pages\" in the deploy section of the gitlab-ci.yaml documentation will automatically be pushed to the repo. Make sure to check with Erik and Alex for your first push. 3. Testing Endpoints These following are the most common commands, used for testing payloads via python. The various functions are presented with various ways of calling. Curl endpoint (Hyperopt Function) curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/hyperopt vai-utils method (Predict Function): response = vai_utils.call_predict(payload, headers) Python requests endpoint (Explain Function) response = response(data=\"{}, headers) Although these may be convenient, it will always be better to call the RESTAPI equivalent to ensure repeatability in production environment. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/endpoint","title":"1. Quickstart"},{"location":"quickstart.html#quickstart","text":"","title":"QUICKSTART"},{"location":"quickstart.html#vai-toolkit","text":"VAI-UTILS is the API for interacting the AUTOML suite. It provides a suite of tools and functionalities to automatically leearn, predict, and explain for all types of data. It can be used for most prediction and classification problems. Warning It is not yet capable of enabling chatbot or other generative AI tasks.","title":"VAI Toolkit"},{"location":"quickstart.html#1-building-apps","text":"To get started with VAI-UTILS, with a use a user key and a pipeline with data, follow these steps: Install VAI Toolkit by running the following command: docker build . curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/endpoint","title":"1. Building Apps"},{"location":"quickstart.html#2-servingdeploying-apps","text":"After testing locally, deploying is done automatically using gitlab CI-CD with the correct configurations. With \"pages\" in the deploy section of the gitlab-ci.yaml documentation will automatically be pushed to the repo. Make sure to check with Erik and Alex for your first push.","title":"2. Serving/Deploying Apps"},{"location":"quickstart.html#3-testing-endpoints","text":"These following are the most common commands, used for testing payloads via python. The various functions are presented with various ways of calling. Curl endpoint (Hyperopt Function) curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/hyperopt vai-utils method (Predict Function): response = vai_utils.call_predict(payload, headers) Python requests endpoint (Explain Function) response = response(data=\"{}, headers) Although these may be convenient, it will always be better to call the RESTAPI equivalent to ensure repeatability in production environment. curl -X POST -H \"Content-Type: application/json\" -d '{\"data\": {\"model\": img...}, \"meta_data\":{}}' http://localhost:5000/endpoint","title":"3. Testing Endpoints"},{"location":"tabular_model_params.html","text":"Tabular Model Learning Parameters The tabular_model_params.md file serves as a comprehensive guide to the parameters utilized in our AutoML application specifically for training tabular models. There are two types of parameters: tabular-specific and general. Tabular-specific parameters are grouped under the tabular_model key. This key defines the name of the tabular model and its corresponding parameters. On the other hand, general parameters apply to all models and are used to configure settings such as the optimizer, learning rate, momentum, epochs, batch size, and the number of hidden layers. This arrangement provides a flexible and efficient way to adjust the model parameters, thereby aiding in the creation of highly precise tabular models. Refer to the following for more details. { \"tabular_model_params\" : { \"random_forest\" : { \"n_estimators\" : 100 , \"max_depth\" : 5 , \"min_samples_split\" : 2 , \"min_samples_leaf\" : 1 } }, \"general_params\" : { \"optimizer\" : \"Adam\" , \"learning_rate\" : 0.0001 , \"momentum\" : 0.85 , \"epochs\" : 10 , \"batch_size\" : 64 , \"hidden_lyrs\" : 1 } } Tabular Specific Parameters Below are the following options tabular_model: (str) Name of the model used for tabular data. Currently default model is \"random_forest\". n_estimators: (int) The number of trees in the forest. max_depth: (int) The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. min_samples_split: (int) The minimum number of samples required to split an internal node. min_samples_leaf: (int) The minimum number of samples required to be at a leaf node. Other General Parameters optimizer: (str) The optimization algorithm to use. Example: \"Adam\". learning_rate: (float) The learning rate for the optimizer. Example: 1e-4. momentum: (float) The momentum factor for the optimizer. Example: 0.85. epochs: (int) The number of training epochs. Example: 1. batch_size: (int) The batch size for training. Example: 64. hidden_lyrs: (int) The number of hidden layers in the model. Example: 1.","title":"3. Tabular Models"},{"location":"tabular_model_params.html#tabular-model-learning-parameters","text":"The tabular_model_params.md file serves as a comprehensive guide to the parameters utilized in our AutoML application specifically for training tabular models. There are two types of parameters: tabular-specific and general. Tabular-specific parameters are grouped under the tabular_model key. This key defines the name of the tabular model and its corresponding parameters. On the other hand, general parameters apply to all models and are used to configure settings such as the optimizer, learning rate, momentum, epochs, batch size, and the number of hidden layers. This arrangement provides a flexible and efficient way to adjust the model parameters, thereby aiding in the creation of highly precise tabular models. Refer to the following for more details. { \"tabular_model_params\" : { \"random_forest\" : { \"n_estimators\" : 100 , \"max_depth\" : 5 , \"min_samples_split\" : 2 , \"min_samples_leaf\" : 1 } }, \"general_params\" : { \"optimizer\" : \"Adam\" , \"learning_rate\" : 0.0001 , \"momentum\" : 0.85 , \"epochs\" : 10 , \"batch_size\" : 64 , \"hidden_lyrs\" : 1 } }","title":"Tabular Model Learning Parameters"},{"location":"tabular_model_params.html#tabular-specific-parameters","text":"Below are the following options tabular_model: (str) Name of the model used for tabular data. Currently default model is \"random_forest\". n_estimators: (int) The number of trees in the forest. max_depth: (int) The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. min_samples_split: (int) The minimum number of samples required to split an internal node. min_samples_leaf: (int) The minimum number of samples required to be at a leaf node.","title":"Tabular Specific Parameters"},{"location":"tabular_model_params.html#other-general-parameters","text":"optimizer: (str) The optimization algorithm to use. Example: \"Adam\". learning_rate: (float) The learning rate for the optimizer. Example: 1e-4. momentum: (float) The momentum factor for the optimizer. Example: 0.85. epochs: (int) The number of training epochs. Example: 1. batch_size: (int) The batch size for training. Example: 64. hidden_lyrs: (int) The number of hidden layers in the model. Example: 1.","title":"Other General Parameters"},{"location":"text_model_params.html","text":"Text Model Learning Parameters The text_model_params.md file serves as a comprehensive guide to the parameters utilized in our AutoML application specifically for training text models. There are two types of parameters: text-specific and general. Text-specific parameters are grouped under the text_model key. This key defines the name of the text model and its corresponding parameters. On the other hand, general parameters apply to all models and are used to configure settings such as the optimizer, learning rate, momentum, epochs, batch size, and the number of hidden layers. This arrangement provides a flexible and efficient way to adjust the model parameters, thereby aiding in the creation of highly precise text models. Refer to the following for more details. { \"text_model_params\" : { \"text_model\" : \"small_bert/bert_en_uncased_L-2_H-128_A-2\" , \"use_dropout_text_layer\" : true , \"dropout_rate_text_layer\" : 0.2 , \"fine_tune_text_model\" : false }, \"general_params\" : { \"optimizer\" : \"Adam\" , \"learning_rate\" : 0.0001 , \"momentum\" : 0.85 , \"epochs\" : 10 , \"batch_size\" : 64 , \"hidden_lyrs\" : 1 } } Params text_model : (str) This is the name of the pre-trained Language model used to generate text embeddings. Currently, we only use sentence embeddings (pooled output of model) and not individual word embeddings, as per word/token embeddings are computationally very expensive. The default model is \"small_bert/bert_en_uncased_L-2_H-128_A-2\". (NOTE: Names of different models can be copied/taken from text_pretrained.py). use_dropout_text_layer : (bool) If set to True, dropout is used to set some units activation to zero. This acts as a regularization mechanism. This is optional and defaults to True. dropout_rate_text_layer : (float 0-1) If \"use_dropout_text_layer\" is True, then this is the fraction of activation units to set to zero to act as a regularization mechanism. This is optional and defaults to 0.2. fine_tune_text_model : (bool) If set to True, the text model \"trainable\" parameter is set to True, and the text model weights are updated with training. Otherwise, the weights of the model are frozen, and only used to generate embeddings. It is recommended to be set to False, unless the data volume is huge. Other General Parameters optimizer : (str) The optimization algorithm to use. Example: \"Adam\". learning_rate : (float) The learning rate for the optimizer. Example: 1e-4. momentum : (float) The momentum factor for the optimizer. Example: 0.85. epochs : (int) The number of training epochs. Example: 1. batch_size : (int) The batch size for training. Example: 64. hidden_lyrs : (int) The number of hidden layers in the model. Example: 1.","title":"2. Text Models"},{"location":"text_model_params.html#text-model-learning-parameters","text":"The text_model_params.md file serves as a comprehensive guide to the parameters utilized in our AutoML application specifically for training text models. There are two types of parameters: text-specific and general. Text-specific parameters are grouped under the text_model key. This key defines the name of the text model and its corresponding parameters. On the other hand, general parameters apply to all models and are used to configure settings such as the optimizer, learning rate, momentum, epochs, batch size, and the number of hidden layers. This arrangement provides a flexible and efficient way to adjust the model parameters, thereby aiding in the creation of highly precise text models. Refer to the following for more details. { \"text_model_params\" : { \"text_model\" : \"small_bert/bert_en_uncased_L-2_H-128_A-2\" , \"use_dropout_text_layer\" : true , \"dropout_rate_text_layer\" : 0.2 , \"fine_tune_text_model\" : false }, \"general_params\" : { \"optimizer\" : \"Adam\" , \"learning_rate\" : 0.0001 , \"momentum\" : 0.85 , \"epochs\" : 10 , \"batch_size\" : 64 , \"hidden_lyrs\" : 1 } }","title":"Text Model Learning Parameters"},{"location":"text_model_params.html#params","text":"text_model : (str) This is the name of the pre-trained Language model used to generate text embeddings. Currently, we only use sentence embeddings (pooled output of model) and not individual word embeddings, as per word/token embeddings are computationally very expensive. The default model is \"small_bert/bert_en_uncased_L-2_H-128_A-2\". (NOTE: Names of different models can be copied/taken from text_pretrained.py). use_dropout_text_layer : (bool) If set to True, dropout is used to set some units activation to zero. This acts as a regularization mechanism. This is optional and defaults to True. dropout_rate_text_layer : (float 0-1) If \"use_dropout_text_layer\" is True, then this is the fraction of activation units to set to zero to act as a regularization mechanism. This is optional and defaults to 0.2. fine_tune_text_model : (bool) If set to True, the text model \"trainable\" parameter is set to True, and the text model weights are updated with training. Otherwise, the weights of the model are frozen, and only used to generate embeddings. It is recommended to be set to False, unless the data volume is huge.","title":"Params"},{"location":"text_model_params.html#other-general-parameters","text":"optimizer : (str) The optimization algorithm to use. Example: \"Adam\". learning_rate : (float) The learning rate for the optimizer. Example: 1e-4. momentum : (float) The momentum factor for the optimizer. Example: 0.85. epochs : (int) The number of training epochs. Example: 1. batch_size : (int) The batch size for training. Example: 64. hidden_lyrs : (int) The number of hidden layers in the model. Example: 1.","title":"Other General Parameters"},{"location":"training_params.html","text":"The Hyper-Parameters Optimization The training parameters are stored in a dictionary called h_params . This dictionary contains the following key-value pairs: General Training Parameters optimizer : (str) Name of optimizer, must be one of \"Adam\", \"Nadam\", \"RMSProp\", or \"SGD\". Optional, defaults to \"SGD\", if no value provided or wrong value provided. learning_rate : (float, 0-1) Learning rate for the optimizer. Optional, defaults to 1.0e-3, if no value provided. momentum : (float, 0-1) Momentum for the optimizer (which uses it, like SGD). Optional, defaults to 0.9, if no value provided. epochs : (int) Total no. of training epochs. An epoch is an iteration over the entire x and y data provided. Optional, defaults to 10, if no value provided. batch_size : (int, range: 16,32,64,128,256,512) No of samples in each batch of data for training. Batch size is used while creating tensorflow dataset object. Optional, defaults to 32, if no value provided. validation_split : (float, range: 0-0.5) Fraction of data to keep for validation of model, and not use in training. Optional, defaults to 0.2, if no value provided (means that only 80% data used in training, and 20% to test model). use_learning_rate_scheduler : (bool) whether to use Learning rate scheduler for the optimizer. If True, we use tf.keras.callbacks.LearningRateScheduler to keep learning rate constant for first 10 epochs, and then decay it exponentially. This allows the model to converge quickly initially and then settle at the right minima, and not oscillate. Optional, defaults to False, if no value provided. use_remote_monitor : (bool) If True, training logs are send to some remote server for display. Optional, defaults to False, if no value provided. Hidden Layers Training Parameters hidden_lyrs : (int: 0-10) No. of hidden/deep dense layers in the network. Each layer shall have half the number of units as compared to last layer. Each layer shall have dimension (BATCH_SIZE, HIDDEN_UNITS). Can be 0, which means no hidden/deep layers. (NOTE:- These does not include the last fully connected dense layer for each output, which shall always be there.) Optional, defaults to 2, if no value provided or wrong value provided. min_hidden_units : (int 1- anything) No. of units in last hidden/deep layer. Each upper layer shall have double the units of lower layer. So, if min_hidden_units = 32, last layer shall have 32 units, 2nd last shall have 64 units, 3rd last 128 units, and so on. Optional, defaults to 8, if no value provided or wrong value provided. hidden_lyrs_activation_function : (str) Activation function to use in hidden layers in neural network. Can use any of commonly used functions like \"sigmoid\", \"softmax\", \"tanh\", \"relu\" etc. which are accepted by tensorflow network layers. Can't use \"leaky_relu\" for now, as it requires a new layer, instead of simple activation function in same layer. Optional, defaults to \"relu\". use_dropout_hidden_lyrs : (bool) If True, dropout is used to set some units activation to zero. Acts as regularization mechanism. Optional, defaults to True. dropout_rate_hidden_lyrs : (float 0-1) If \"use_dropout_hidden_lyrs\" is True, then the fraction of activation units to set to zero to act as regularization mechanism. Optional, defaults to 0.2.","title":"The Hyper-Parameters Optimization"},{"location":"training_params.html#the-hyper-parameters-optimization","text":"The training parameters are stored in a dictionary called h_params . This dictionary contains the following key-value pairs:","title":"The Hyper-Parameters Optimization"},{"location":"training_params.html#general-training-parameters","text":"optimizer : (str) Name of optimizer, must be one of \"Adam\", \"Nadam\", \"RMSProp\", or \"SGD\". Optional, defaults to \"SGD\", if no value provided or wrong value provided. learning_rate : (float, 0-1) Learning rate for the optimizer. Optional, defaults to 1.0e-3, if no value provided. momentum : (float, 0-1) Momentum for the optimizer (which uses it, like SGD). Optional, defaults to 0.9, if no value provided. epochs : (int) Total no. of training epochs. An epoch is an iteration over the entire x and y data provided. Optional, defaults to 10, if no value provided. batch_size : (int, range: 16,32,64,128,256,512) No of samples in each batch of data for training. Batch size is used while creating tensorflow dataset object. Optional, defaults to 32, if no value provided. validation_split : (float, range: 0-0.5) Fraction of data to keep for validation of model, and not use in training. Optional, defaults to 0.2, if no value provided (means that only 80% data used in training, and 20% to test model). use_learning_rate_scheduler : (bool) whether to use Learning rate scheduler for the optimizer. If True, we use tf.keras.callbacks.LearningRateScheduler to keep learning rate constant for first 10 epochs, and then decay it exponentially. This allows the model to converge quickly initially and then settle at the right minima, and not oscillate. Optional, defaults to False, if no value provided. use_remote_monitor : (bool) If True, training logs are send to some remote server for display. Optional, defaults to False, if no value provided.","title":"General Training Parameters"},{"location":"training_params.html#hidden-layers-training-parameters","text":"hidden_lyrs : (int: 0-10) No. of hidden/deep dense layers in the network. Each layer shall have half the number of units as compared to last layer. Each layer shall have dimension (BATCH_SIZE, HIDDEN_UNITS). Can be 0, which means no hidden/deep layers. (NOTE:- These does not include the last fully connected dense layer for each output, which shall always be there.) Optional, defaults to 2, if no value provided or wrong value provided. min_hidden_units : (int 1- anything) No. of units in last hidden/deep layer. Each upper layer shall have double the units of lower layer. So, if min_hidden_units = 32, last layer shall have 32 units, 2nd last shall have 64 units, 3rd last 128 units, and so on. Optional, defaults to 8, if no value provided or wrong value provided. hidden_lyrs_activation_function : (str) Activation function to use in hidden layers in neural network. Can use any of commonly used functions like \"sigmoid\", \"softmax\", \"tanh\", \"relu\" etc. which are accepted by tensorflow network layers. Can't use \"leaky_relu\" for now, as it requires a new layer, instead of simple activation function in same layer. Optional, defaults to \"relu\". use_dropout_hidden_lyrs : (bool) If True, dropout is used to set some units activation to zero. Acts as regularization mechanism. Optional, defaults to True. dropout_rate_hidden_lyrs : (float 0-1) If \"use_dropout_hidden_lyrs\" is True, then the fraction of activation units to set to zero to act as regularization mechanism. Optional, defaults to 0.2.","title":"Hidden Layers Training Parameters"}]}